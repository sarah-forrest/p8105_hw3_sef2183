---
title: "p8105_hw3_sef2183"
author: "Sarah Forrest"
date: "2022-10-06"
output: github_document
---

# Problem 0

```{r setup, include=FALSE}
knitr::opts_chunk$set(collapse = TRUE, message = FALSE)
```

```{r load packages}
library(tidyverse)
library(patchwork)
```

# Problem 1

```{r read in problem 1 data}
library(p8105.datasets)
data("instacart")
```

## Description of the dataset:
* Size and structure of the data
* Describe key variables
* Illustrative examples of observations.

## Dataset questions (commenting on the results of each):
* How many aisles are there, and which aisles are the most items ordered from?
* Make a plot that shows the number of items ordered in each aisle, limiting this to aisles with more than 10000 items ordered. 
* Arrange aisles sensibly, and organize your plot so others can read it.
* Make a table showing the three most popular items in *each of the aisles* “baking ingredients”, “dog food care”, and “packaged vegetables fruits”. Include the number of times each item is ordered in your table.
* Make a table showing the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week; format this table for human readers (i.e. produce a 2 x 7 table).

# Problem 2
Below, the accelerometer data from `accel_data.csv` is read in and the variable names are cleaned using `clean_names()`. Then, `pivot_longer()` is used to manipulate the dataset from wide to long format. To do this, all variable names beginning with "activity" were split into 2 different variables: the variable names were changed to `minute` and the prefix "activity_" was removed so that the variable values conatined only the minute number, and the values were changed to `activity_count`, indicating the amount of activity read by the accelerometer during each 1 minute window. Finally, a new variable called `weekday_weekend` was created to indicate whether the day of the week is a weekday or a weekend day. 
```{r read and manipulate problem 2 data}
accel_df = 
  read_csv("data/accel_data.csv") %>%
  janitor::clean_names() %>%
  pivot_longer(
    starts_with("activity"),
    names_to = "minute",
    names_prefix = "activity_", 
    values_to = "activity_count") %>%
  mutate(weekday_weekend = case_when(day == "Monday" ~ "weekday",
                                     day == "Tuesday" ~ "weekday",
                                     day == "Wednesday" ~ "weekday",
                                     day == "Thursday" ~ "weekday",
                                     day == "Friday" ~ "weekday",
                                     day == "Saturday" ~ "weekend",
                                     day == "Sunday" ~ "weekend"))

# What is meant by encode data with reasonable variable classes
```

## Dataset description
* The variables in the resulting dataset include: `week`, `day_id` (day count number), `day` (day of the week), `minute`, `activity_count`, and `weekday_weekend` (either weekday or weekend)
* The resulting dataset contains `r nrow(accel_df)` rows/observations and `r ncol(accel_df)` columns/variables.

## Table of total activity over each day
Below, the tidied accelerometer dataset was aggregated across minutes using `group_by()` to group the data together by the `DAY_ID` variable. Then a `total_activity` variable was created by summing the `activity_count` variables for each 1 minute window throughout the day to indicate the total activity read by the accelerometer during each day of the study. Finally, only the relevant variables `day_id`, `week`, `day`, and `total_activity` were selected from the dataset using `select()` and a table was created to show the daily totals for each of the 35 days of the study using `kable()` from the `knitr` package. 

TOTAL FOR DAY_ID OR DAY OF THE WEEK?

```{r problem 2 total activity table}
accel_df %>%
  group_by(day_id, week, day) %>%
  summarize(
    total_activity = sum(activity_count)) %>% 
  select(day_id, week, day, total_activity) %>% 
  knitr::kable()
```

* It's very difficult to see any trends that are apparent from this table. I immediately noticed that the last 2 Saturdays in the study (days 24 and 31) had a much lower total activity count than the other days in the study. However, the previous Saturdays in the study had relatively similar total activity counts to the rest of the days in the study, so this isn't a trend that can be seen through the entire dataset. Visualization may be required to see any trends, if they are apparent in this dataset. 

## Plot of the 24-hour activity time courses for each day 
Below, a single panel-plot was created using `ggplot()` to show the 24-hour activity time courses for each day, using color to indicate the day of the week.

```{r problem 2 plot}
accel_df %>%
  group_by(day_id, week, day) %>%
  summarize(
    total_activity = sum(activity_count)) %>% 
  ggplot(aes(x = day, y = total_activity, color = day)) + 
    geom_point() + geom_line() + 
    theme(legend.position = "bottom")
```

* PATTERNS AND CONCLUSIONS

# Problem 3

```{r read in problem 3 data}
library(p8105.datasets)
data("ny_noaa")
```

## Description of the dataset:
* The size of the dataset is
* The structure of the dataset is
* Key variables in the dataset are (description)
* (indicating the extent to which missing data is an issue)

id: Weather station ID
date: Date of observation
prcp: Precipitation (tenths of mm)
snow: Snowfall (mm)
snwd: Snow depth (mm)
tmax: Maximum temperature (tenths of degrees C)
tmin: Minimum temperature (tenths of degrees C)

```{r manipulate problem 3 data}
ny_noaa_df = 
  ny_noaa %>%
  janitor::clean_names() %>%
  separate(date, into = c("year", "month", "day"), sep = '-') %>%
  mutate(
    tmax = as.numeric(tmax),
    tmin = as.numeric(tmin)) %>%
  mutate(
    prcp = prcp / 10, 
    tmin = tmin / 10,
    tmax = tmax / 10) # Ensure observations for temperature, precipitation, and snowfall are given in reasonable units?
```

## Dataset questions:
### Most common values of snowfall
#### Distribution histogram

```{r problem 3 snowfall plot}
ggplot(ny_noaa_df, aes(x = snow)) + geom_histogram()
```

#### Table
```{r problem 3 snowfall count}
ny_noaa_df %>%
  count(snow, name = "count") %>% 
  knitr::kable()
```

From both the distribution histogram of snowfall and the table with the counts for each value of snowfall, the most commonly observed value of snowfall is _________. The reason is because ___________.

## Plot of average max temperature in January and in July in each station across years
Make a two-panel plot

```{r problem 3 max temp plots}
jan_tmax_p = ny_noaa_df %>%
  filter(month == "01") %>% 
  group_by(year) %>% 
  mutate(mean_tmax = mean(tmax, na.rm = TRUE)) %>% 
  ggplot(aes(x = year, y = mean_tmax)) + 
  theme(axis.text.x = element_text(angle = 90,hjust = 1)) + geom_point() +
  ggtitle("Average max temperature in January in each station across years")

jul_tmax_p = ny_noaa_df %>%
  filter(month == "07") %>% 
  group_by(year) %>% 
  mutate(mean_tmax = mean(tmax, na.rm = TRUE)) %>% 
  ggplot(aes(x = year, y = mean_tmax)) + 
  theme(axis.text.x = element_text(angle = 90,hjust = 1)) + geom_point() +
  ggtitle("Average max temperature in July in each station across years")

jan_tmax_p + jul_tmax_p
```

* There [IS/IS NOT] an observable interpretable structure
* There [ARE/ARE NOT] outliers

## Plot of tmax vs tmin for the full dataset (panel 1) and the distribution of snowfall values greater than 0 and less than 100 separately by year (panel 2)
Make a two-panel plot showing 

```{r problem 3 tmax vs tmin and snowfall plots}
i_p = ny_noaa_df %>%
  filter(month == "01") %>% 
  ggplot(aes(x = tmin, y = tmax)) +  
  theme(legend.position = "bottom") + geom_hex() +
  ggtitle("Max temp vs min temperature")

ii_p = ny_noaa_df %>%
  filter(snow < 0 | snow > 100) %>% 
  group_by(year) %>% 
  ggplot(aes(x = year, y = snow)) + 
  theme(axis.text.x = element_text(angle = 90,hjust = 1)) + geom_point() +
  ggtitle("Distribution of extreme snowfall values by year")

i_p + ii_p
```
