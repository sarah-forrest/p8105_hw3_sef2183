---
title: "p8105_hw3_sef2183"
author: "Sarah Forrest"
date: "2022-10-06"
output: github_document
---

# Problem 0

```{r setup, include=FALSE}
knitr::opts_chunk$set(collapse = TRUE, message = FALSE)
```

```{r load packages}
library(tidyverse)
library(patchwork)
```

# Problem 1

```{r read in problem 1 data}
library(p8105.datasets)
data("instacart")
```

## Description of the dataset:
* Size and structure of the data
* Describe key variables
* Illustrative examples of observations.

## Dataset questions (commenting on the results of each):
* How many aisles are there, and which aisles are the most items ordered from?
* Make a plot that shows the number of items ordered in each aisle, limiting this to aisles with more than 10000 items ordered. 
* Arrange aisles sensibly, and organize your plot so others can read it.
* Make a table showing the three most popular items in *each of the aisles* “baking ingredients”, “dog food care”, and “packaged vegetables fruits”. Include the number of times each item is ordered in your table.
* Make a table showing the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week; format this table for human readers (i.e. produce a 2 x 7 table).

# Problem 2
```{r read and manipulate problem 2 data}
accel_df = 
  read_csv("data/accel_data.csv") %>%
  janitor::clean_names() %>%
  pivot_longer(
    starts_with("activity"),
    names_to = "minute",
    names_prefix = "activity_", 
    values_to = "activity_count") %>%
  mutate(weekday_weekend = case_when(day == "Monday" ~ "weekday",
                                     day == "Tuesday" ~ "weekday",
                                     day == "Wednesday" ~ "weekday",
                                     day == "Thursday" ~ "weekday",
                                     day == "Friday" ~ "weekday",
                                     day == "Saturday" ~ "weekend",
                                     day == "Sunday" ~ "weekend"))

# What is meant by encode data with reasonable variable classes
```

## Dataset description
* The variables in the resulting dataset include: 
* The resulting dataset contains `r nrow(accel_df)` rows/observations and `r ncol(accel_df)` columns/variables.

## Table of total activity over each day
TOTAL FOR DAY ID OR DAY?

```{r problem 2 total activity table}
accel_df %>%
  group_by(day_id, week, day) %>%
  summarize(
    total_activity = sum(activity_count)) %>% 
  select(day_id, week, day, total_activity) %>% 
  knitr::kable()
```

* THE TRENDS APPARENT ARE:

## Plot of the 24-hour activity time courses for each day 

```{r problem 2 plot}
accel_df %>%
  group_by(day_id, week, day) %>%
  summarize(
    total_activity = sum(activity_count)) %>% 
  ggplot(aes(x = day, y = total_activity, color = day)) + 
    geom_point() + geom_line() + 
    theme(legend.position = "bottom")
```

* PATTERNS AND CONCLUSIONS

# Problem 3

```{r read in problem 3 data}
library(p8105.datasets)
data("ny_noaa")
```

## Description of the dataset:
* The size of the dataset is
* The structure of the dataset is
* Key variables in the dataset are (description)
* (indicating the extent to which missing data is an issue)

id: Weather station ID
date: Date of observation
prcp: Precipitation (tenths of mm)
snow: Snowfall (mm)
snwd: Snow depth (mm)
tmax: Maximum temperature (tenths of degrees C)
tmin: Minimum temperature (tenths of degrees C)

```{r manipulate problem 3 data}
ny_noaa_df = 
  ny_noaa %>%
  janitor::clean_names() %>%
  separate(date, into = c("year", "month", "day"), sep = '-') %>%
  mutate(
    tmax = as.numeric(tmax),
    tmin = as.numeric(tmin)) %>%
  mutate(
    prcp = prcp / 10, 
    tmin = tmin / 10,
    tmax = tmax / 10) # Ensure observations for temperature, precipitation, and snowfall are given in reasonable units?
```

## Dataset questions:
### Most common values of snowfall
#### Distribution histogram

```{r problem 3 snowfall plot}
ggplot(ny_noaa_df, aes(x = snow)) + geom_histogram()
```

#### Table
```{r problem 3 snowfall count}
ny_noaa_df %>%
  count(snow, name = "count") %>% 
  knitr::kable()
```

From both the distribution histogram of snowfall and the table with the counts for each value of snowfall, the most commonly observed value of snowfall is _________. The reason is because ___________.

## Plot of average max temperature in January and in July in each station across years
Make a two-panel plot

```{r problem 3 max temp plots}
jan_tmax_p = ny_noaa_df %>%
  filter(month == "01") %>% 
  group_by(year) %>% 
  mutate(mean_tmax = mean(tmax, na.rm = TRUE)) %>% 
  ggplot(aes(x = year, y = mean_tmax)) + 
  theme(axis.text.x = element_text(angle = 90,hjust = 1)) + geom_point() +
  ggtitle("Average max temperature in January in each station across years")

jul_tmax_p = ny_noaa_df %>%
  filter(month == "07") %>% 
  group_by(year) %>% 
  mutate(mean_tmax = mean(tmax, na.rm = TRUE)) %>% 
  ggplot(aes(x = year, y = mean_tmax)) + 
  theme(axis.text.x = element_text(angle = 90,hjust = 1)) + geom_point() +
  ggtitle("Average max temperature in July in each station across years")

jan_tmax_p + jul_tmax_p
```

* There [IS/IS NOT] an observable interpretable structure
* There [ARE/ARE NOT] outliers

## Plot of tmax vs tmin for the full dataset (panel 1) and the distribution of snowfall values greater than 0 and less than 100 separately by year (panel 2)
Make a two-panel plot showing 

```{r problem 3 tmax vs tmin and snowfall plots}
i_p = ny_noaa_df %>%
  filter(month == "01") %>% 
  ggplot(aes(x = tmin, y = tmax)) +  
  theme(legend.position = "bottom") + geom_hex() +
  ggtitle("Max temp vs min temperature")

ii_p = ny_noaa_df %>%
  filter(snow < 0 | snow > 100) %>% 
  group_by(year) %>% 
  ggplot(aes(x = year, y = snow)) + 
  theme(axis.text.x = element_text(angle = 90,hjust = 1)) + geom_point() +
  ggtitle("Distribution of extreme snowfall values by year")

i_p + ii_p
```
