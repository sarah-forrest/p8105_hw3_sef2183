p8105_hw3_sef2183
================
Sarah Forrest
2022-10-05

# Problem 0

``` r
library(tidyverse)
library(patchwork)
```

# Problem 1

``` r
library(p8105.datasets)
data("instacart")
```

## Description of the dataset:

-   This dataset contains 1384617 rows and 15 columns, with each row
    resprenting a single product from an instacart order.
-   Key variables include identifiers for user, order, and product; the
    order in which each product was added to the cart. There are several
    order-level variables, describing the day and time of the order, and
    number of days since prior order. Then there are several
    item-specific variables, describing the product name (e.g. Yogurt,
    Avocado), department (e.g. dairy and eggs, produce), and aisle
    (e.g. yogurt, fresh fruits), and whether the item has been ordered
    by this user in the past.
-   In total, there are 39123 products found in 131209 orders from
    131209 distinct users.

## Dataset questions:

Below is a table summarizing the number of items ordered from aisle. In
total, there are 134 aisles, with fresh vegetables and fresh fruits
holding the most items ordered by far:

``` r
instacart %>% 
  count(aisle) %>% 
  arrange(desc(n))
## # A tibble: 134 × 2
##    aisle                              n
##    <chr>                          <int>
##  1 fresh vegetables              150609
##  2 fresh fruits                  150473
##  3 packaged vegetables fruits     78493
##  4 yogurt                         55240
##  5 packaged cheese                41699
##  6 water seltzer sparkling water  36617
##  7 milk                           32644
##  8 chips pretzels                 31269
##  9 soy lactosefree                26240
## 10 bread                          23635
## # … with 124 more rows
```

Below is a plot that shows the number of items ordered in each aisle.
Here, aisles are ordered by ascending number of items:

``` r
instacart %>% 
  count(aisle) %>% 
  filter(n > 10000) %>% 
  mutate(aisle = fct_reorder(aisle, n)) %>% 
  ggplot(aes(x = aisle, y = n)) + 
  geom_point() + 
  labs(title = "Number of items ordered in each aisle") +
  theme(axis.text.x = element_text(angle = 60, hjust = 1))
```

![](p8105_hw3_sef2183_files/figure-gfm/problem%201%20aisle%20item%20count%20plot-1.png)<!-- -->

Below is a table showing the three most popular items in aisles
`baking ingredients`, `dog food care`, and `packaged vegetables fruits`,
and includes the number of times each item is ordered:

``` r
instacart %>% 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>%
  group_by(aisle) %>% 
  count(product_name) %>% 
  mutate(rank = min_rank(desc(n))) %>% 
  filter(rank < 4) %>% 
  arrange(desc(n)) %>%
  knitr::kable()
```

| aisle                      | product_name                                  |    n | rank |
|:---------------------------|:----------------------------------------------|-----:|-----:|
| packaged vegetables fruits | Organic Baby Spinach                          | 9784 |    1 |
| packaged vegetables fruits | Organic Raspberries                           | 5546 |    2 |
| packaged vegetables fruits | Organic Blueberries                           | 4966 |    3 |
| baking ingredients         | Light Brown Sugar                             |  499 |    1 |
| baking ingredients         | Pure Baking Soda                              |  387 |    2 |
| baking ingredients         | Cane Sugar                                    |  336 |    3 |
| dog food care              | Snack Sticks Chicken & Rice Recipe Dog Treats |   30 |    1 |
| dog food care              | Organix Chicken & Brown Rice Recipe           |   28 |    2 |
| dog food care              | Small Dog Biscuits                            |   26 |    3 |

Below is a table showing the mean hour of the day at which Pink Lady
Apples and Coffee Ice Cream are ordered on each day of the week. This
table has been formatted in an untidy manner for human readers:

``` r
instacart %>%
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>%
  group_by(product_name, order_dow) %>%
  summarize(mean_hour = mean(order_hour_of_day)) %>%
  spread(key = order_dow, value = mean_hour) %>%
  knitr::kable(digits = 2)
```

| product_name     |     0 |     1 |     2 |     3 |     4 |     5 |     6 |
|:-----------------|------:|------:|------:|------:|------:|------:|------:|
| Coffee Ice Cream | 13.77 | 14.32 | 15.38 | 15.32 | 15.22 | 12.26 | 13.83 |
| Pink Lady Apples | 13.44 | 11.36 | 11.70 | 14.25 | 11.55 | 12.78 | 11.94 |

Pink Lady Apples are generally purchased slightly earlier in the day
than Coffee Ice Cream, with the exception of day 5.

# Problem 2

Below, the accelerometer data from `accel_data.csv` is read in and the
variable names are cleaned. Then, `pivot_longer()` is used to manipulate
the dataset from wide to long format. To do this, all variable names
beginning with “activity” (`activity_1` to `activity_1440`) were
transformed into 2 different variables: one denoting the minute of the
day and one denoting the activity measure. Finally, a new weekday
vs. weekend variable was created.

``` r
accel_df = 
  read_csv("data/accel_data.csv") %>%
  janitor::clean_names() %>%
  pivot_longer(
    starts_with("activity"),
    names_to = "minute",
    names_prefix = "activity_", 
    values_to = "activity_count") %>%
  mutate(weekday_weekend = case_when(day == "Monday" ~ "weekday",
                                     day == "Tuesday" ~ "weekday",
                                     day == "Wednesday" ~ "weekday",
                                     day == "Thursday" ~ "weekday",
                                     day == "Friday" ~ "weekday",
                                     day == "Saturday" ~ "weekend",
                                     day == "Sunday" ~ "weekend"))
```

## Dataset description

-   The variables in the resulting dataset include: `week`, `day_id`
    (day count number), `day` (day of the week), `minute`,
    `activity_count`, and `weekday_weekend` (either weekday or weekend)
-   The resulting dataset contains 50400 rows/observations and 6
    columns/variables.

## Table of total activity over each day

Below, the tidied accelerometer dataset was aggregated across minutes
and grouped together by the `day_id` variable. Then a `total_activity`
variable was created by summing the `activity_count` variables for each
1 minute window throughout each day of the study. Finally, only the
relevant variables were selected from the dataset and a table was
created to show the daily totals for each of the 35 days of the study
using `kable()`.

``` r
accel_df %>%
  group_by(day_id, week, day) %>%
  summarize(
    total_activity = sum(activity_count)) %>% 
  select(day_id, week, day, total_activity) %>% 
  knitr::kable()
```

| day_id | week | day       | total_activity |
|-------:|-----:|:----------|---------------:|
|      1 |    1 | Friday    |      480542.62 |
|      2 |    1 | Monday    |       78828.07 |
|      3 |    1 | Saturday  |      376254.00 |
|      4 |    1 | Sunday    |      631105.00 |
|      5 |    1 | Thursday  |      355923.64 |
|      6 |    1 | Tuesday   |      307094.24 |
|      7 |    1 | Wednesday |      340115.01 |
|      8 |    2 | Friday    |      568839.00 |
|      9 |    2 | Monday    |      295431.00 |
|     10 |    2 | Saturday  |      607175.00 |
|     11 |    2 | Sunday    |      422018.00 |
|     12 |    2 | Thursday  |      474048.00 |
|     13 |    2 | Tuesday   |      423245.00 |
|     14 |    2 | Wednesday |      440962.00 |
|     15 |    3 | Friday    |      467420.00 |
|     16 |    3 | Monday    |      685910.00 |
|     17 |    3 | Saturday  |      382928.00 |
|     18 |    3 | Sunday    |      467052.00 |
|     19 |    3 | Thursday  |      371230.00 |
|     20 |    3 | Tuesday   |      381507.00 |
|     21 |    3 | Wednesday |      468869.00 |
|     22 |    4 | Friday    |      154049.00 |
|     23 |    4 | Monday    |      409450.00 |
|     24 |    4 | Saturday  |        1440.00 |
|     25 |    4 | Sunday    |      260617.00 |
|     26 |    4 | Thursday  |      340291.00 |
|     27 |    4 | Tuesday   |      319568.00 |
|     28 |    4 | Wednesday |      434460.00 |
|     29 |    5 | Friday    |      620860.00 |
|     30 |    5 | Monday    |      389080.00 |
|     31 |    5 | Saturday  |        1440.00 |
|     32 |    5 | Sunday    |      138421.00 |
|     33 |    5 | Thursday  |      549658.00 |
|     34 |    5 | Tuesday   |      367824.00 |
|     35 |    5 | Wednesday |      445366.00 |

-   It’s very difficult to see any trends that are apparent from this
    table. I immediately noticed that the last 2 Saturdays in the study
    (days 24 and 31) had a much lower total activity count than the
    other days in the study. However, the previous Saturdays in the
    study had relatively similar total activity counts to the rest of
    the days in the study, so this isn’t a trend that can be seen
    through the entire dataset. Visualization may be required to see any
    trends, if they are apparent in this dataset.

## Plot of the 24-hour activity time courses for each day

Below is a single panel-plot showing the 24-hour activity time courses
for each day, using color to indicate the day of the week. The data was
grouped by day of the week, then `ggplot()` was called to create a
scatterplot with `minute` on the x axis and `activity_count` (data read
from the accelerometer in 1 minute intervals) on the y axis.

``` r
accel_df %>%
  group_by(day) %>%
  ggplot(aes(x = minute, y = activity_count, color = day)) + geom_point() + 
  theme(legend.position = "bottom")
```

![](p8105_hw3_sef2183_files/figure-gfm/problem%202%20plot-1.png)<!-- -->

This plot shows the individual’s activity course throughout the entire
1440 minutes within a 24-hour period for each day of the week throughout
the 5 weeks if the study observation period. However, since there are so
many minutes in a 24-hour period, the plot is messy and the values on
the x axis are difficult to read. Even with this difficulty, it is still
possible to see some patterns and trends in the data:

-   For all days of the week, there are lower activity counts that can
    be observed mid morning, at around 9:30am-10:30am (estimated,
    because exact minutes can not be read on the x axis)
-   On Tuesdays, the individual doesn’t appear to spend any minutes with
    activity counts over 3750, indicating that the individual seems to
    have less/lighter activity on Tuesdays.
-   On Sundays, the individual has most of their high activity counts
    later in the day compared to the other days of the week at around
    5:00pm (estimated)
-   On Thursdays, the individual has most of their high activity counts
    around midday at around 1:00pm (estimated)
-   On Fridays, the individual has most of their high activity counts
    earlier in the day at around 5:00am (estimated), with some high
    activity in the early afternoon as well at around 3:00pm (estimated)
-   On Mondays and Wednesdays, the individual has most of their high
    activity counts earlier in the day at around 5:00am (estimated).
-   On Saturdays, the individual has most of their high activity counts
    earlier in the day at around 5:00am (estimated) and a some at late
    at night as well, at around 12:00am (estimated)

# Problem 3

``` r
library(p8105.datasets)
data("ny_noaa")
```

## Description of the dataset:

-   The size of the dataset is 2,595,176 observations (rows) and
    variables 7 variables (columns)
-   The structure of the dataset is in long format, with 1 row for each
    observation date for each weather station.
-   Variables in the dataset include: `id` (weather station ID), `date`
    (observation date), `prcp` (precipitation measured in tenths of a
    mm), `snow` (snowfall measured in mm), `snwd` (snow depth measured
    in mm), `tmax` (maximum temperature measured in tenths of degrees
    C), and `tmin` (minimum temperature measured in tenths of degrees
    C).
-   The dataset contains extensive missing data, since each weather
    station may collect only a subset of the weather variables:

``` r
sum(is.na(ny_noaa$prcp)) 
## [1] 145838
sum(is.na(ny_noaa$snow))
## [1] 381221
sum(is.na(ny_noaa$snwd))
## [1] 591786
sum(is.na(ny_noaa$tmax))
## [1] 1134358
sum(is.na(ny_noaa$tmin))
## [1] 1134420
```

-   There are 145,838 missing observations for `prcp`
-   There are 381,221 missing observations for `snow`
-   There are 591,786 missing observations for `snwd`
-   There are 1,134,358 missing observations for `tmax`
-   There are 1,134,420 missing observations for `tmin`

It’s worth noting that the `tmax` and `tmin` variables have the most
missing observations, and `prcp` has the least number of missing
observations. This alligns with the dataset description which stated
that about one half of the stations report precipitation only.
Therefore, missing data will be more of a problem for analyses involving
`tmax` and `tmin`, but less of a problem for analyses with the other
variables in the dataset.

Below, a dataframe is created from the `ny_noaa` dataset and the
variable names are cleaned and separate variables for `year`, `month`,
and `day` were created by separating the `date` variable. Then, `tmax`
and `tmin` were converted to numeric variables and `tmax`, `tmin`, and
`prcp` were converted to reasonable units. In the description of the
original `ny_noaa` dataset, `tmax`, `tmin`, and `prcp` were reported in
tenths of mm and tenths of degrees Celsius, which is not very easy to
interpret. Therefore, the values were divided by 10 so the variables
were in reasonable units.

``` r
ny_noaa_df = 
  ny_noaa %>%
  janitor::clean_names() %>%
  separate(date, into = c("year", "month", "day"), sep = '-') %>%
  mutate(
    tmax = as.numeric(tmax),
    tmin = as.numeric(tmin)) %>%
  mutate(
    prcp = prcp / 10, 
    tmin = tmin / 10,
    tmax = tmax / 10) 
```

## Dataset questions:

### Most common values of snowfall

#### Distribution histogram

Below is a distribution histogram of values for the snowfall variable
`snow` using `ggplot()`, with values for `snow` on the x axis and a
count on the y axis:

``` r
ggplot(ny_noaa_df, aes(x = snow)) + geom_histogram()
## Warning: Removed 381221 rows containing non-finite values (stat_bin).
```

![](p8105_hw3_sef2183_files/figure-gfm/problem%203%20snowfall%20plot-1.png)<!-- -->

#### Table

Below is a table denoting the counts for each value of the snowfall
variable `snow` using `count()` and the `kable()` function from the
`knitr` package to create the table:

``` r
ny_noaa_df %>%
  count(snow, name = "count") %>% 
  knitr::kable()
```

|  snow |   count |
|------:|--------:|
|   -13 |       1 |
|     0 | 2008508 |
|     3 |    8790 |
|     5 |    9748 |
|     8 |    9962 |
|    10 |    5106 |
|    13 |   23095 |
|    15 |    3672 |
|    18 |    3226 |
|    20 |    4797 |
|    23 |    1959 |
|    25 |   31022 |
|    28 |    2118 |
|    30 |    2814 |
|    33 |    2380 |
|    36 |    1630 |
|    38 |    9197 |
|    41 |    1467 |
|    43 |    1337 |
|    46 |    2123 |
|    48 |     918 |
|    51 |   18274 |
|    53 |    1155 |
|    56 |    1179 |
|    58 |    1198 |
|    61 |     849 |
|    64 |    4506 |
|    66 |     790 |
|    69 |     726 |
|    71 |    1075 |
|    74 |     463 |
|    76 |   10173 |
|    79 |     635 |
|    81 |     811 |
|    84 |     553 |
|    86 |     476 |
|    89 |    2535 |
|    91 |     428 |
|    94 |     404 |
|    97 |     704 |
|    99 |     276 |
|   102 |    6552 |
|   104 |     349 |
|   107 |     504 |
|   109 |     393 |
|   112 |     243 |
|   114 |    1578 |
|   117 |     276 |
|   119 |     248 |
|   122 |     411 |
|   124 |     183 |
|   127 |    3901 |
|   130 |     217 |
|   132 |     310 |
|   135 |     253 |
|   137 |     173 |
|   140 |     994 |
|   142 |     187 |
|   145 |     172 |
|   147 |     268 |
|   150 |     124 |
|   152 |    3131 |
|   155 |     186 |
|   157 |     209 |
|   160 |     149 |
|   163 |     133 |
|   165 |     614 |
|   168 |     115 |
|   170 |     104 |
|   173 |     187 |
|   175 |      80 |
|   178 |    1650 |
|   180 |      93 |
|   183 |     132 |
|   185 |     117 |
|   188 |      77 |
|   191 |     426 |
|   193 |      70 |
|   196 |      75 |
|   198 |     130 |
|   201 |      60 |
|   203 |    1475 |
|   206 |      74 |
|   208 |      98 |
|   211 |      69 |
|   213 |      58 |
|   216 |     292 |
|   218 |      55 |
|   221 |      53 |
|   224 |      61 |
|   226 |      35 |
|   229 |     744 |
|   231 |      43 |
|   234 |      52 |
|   236 |      49 |
|   239 |      39 |
|   241 |     192 |
|   244 |      36 |
|   246 |      37 |
|   249 |      58 |
|   251 |      21 |
|   254 |     786 |
|   257 |      34 |
|   259 |      48 |
|   262 |      28 |
|   264 |      24 |
|   267 |     130 |
|   269 |      19 |
|   272 |      22 |
|   274 |      45 |
|   277 |      20 |
|   279 |     369 |
|   282 |      28 |
|   284 |      37 |
|   287 |      22 |
|   290 |      24 |
|   292 |      81 |
|   295 |      20 |
|   297 |      14 |
|   300 |      24 |
|   302 |      22 |
|   305 |     451 |
|   307 |      17 |
|   310 |      29 |
|   312 |      22 |
|   315 |      13 |
|   318 |      70 |
|   320 |       7 |
|   323 |      22 |
|   325 |      12 |
|   328 |       6 |
|   330 |     226 |
|   333 |       9 |
|   335 |      13 |
|   338 |      17 |
|   340 |      13 |
|   343 |      63 |
|   345 |      17 |
|   348 |       6 |
|   351 |      15 |
|   353 |      12 |
|   356 |     235 |
|   358 |      12 |
|   361 |      15 |
|   363 |      14 |
|   366 |      15 |
|   368 |      32 |
|   371 |       4 |
|   373 |       6 |
|   376 |      12 |
|   378 |       5 |
|   381 |     139 |
|   384 |       6 |
|   386 |       8 |
|   389 |       5 |
|   391 |       1 |
|   394 |      27 |
|   396 |       5 |
|   399 |       4 |
|   401 |      10 |
|   404 |       7 |
|   406 |     116 |
|   409 |       6 |
|   411 |       8 |
|   414 |      12 |
|   417 |       9 |
|   419 |      15 |
|   422 |       5 |
|   424 |       3 |
|   427 |       8 |
|   429 |       1 |
|   432 |      63 |
|   434 |       7 |
|   437 |       8 |
|   439 |       3 |
|   445 |       8 |
|   447 |       5 |
|   450 |       5 |
|   452 |       5 |
|   455 |       4 |
|   457 |     100 |
|   460 |       5 |
|   462 |       3 |
|   465 |       5 |
|   467 |       6 |
|   470 |      20 |
|   472 |       4 |
|   475 |       5 |
|   478 |       4 |
|   480 |       2 |
|   483 |      44 |
|   488 |       4 |
|   490 |       2 |
|   495 |       3 |
|   498 |       2 |
|   503 |       2 |
|   505 |       2 |
|   508 |      54 |
|   511 |       2 |
|   513 |       3 |
|   516 |       2 |
|   518 |       3 |
|   521 |       8 |
|   523 |       2 |
|   526 |       2 |
|   528 |       2 |
|   533 |      16 |
|   536 |       1 |
|   544 |       1 |
|   546 |       6 |
|   549 |       4 |
|   551 |       2 |
|   554 |       4 |
|   556 |       1 |
|   559 |      35 |
|   561 |       2 |
|   564 |       2 |
|   566 |       1 |
|   569 |       1 |
|   572 |       3 |
|   574 |       1 |
|   577 |       1 |
|   579 |       1 |
|   584 |      20 |
|   587 |       1 |
|   589 |       1 |
|   592 |       2 |
|   594 |       3 |
|   597 |       4 |
|   607 |       1 |
|   610 |      35 |
|   612 |       1 |
|   615 |       1 |
|   620 |       1 |
|   622 |       2 |
|   625 |       1 |
|   630 |       2 |
|   632 |       3 |
|   635 |      10 |
|   643 |       2 |
|   645 |       1 |
|   648 |       1 |
|   650 |       1 |
|   660 |      13 |
|   663 |       2 |
|   665 |       1 |
|   686 |       6 |
|   693 |       1 |
|   699 |       4 |
|   704 |       1 |
|   711 |      10 |
|   721 |       2 |
|   734 |       1 |
|   737 |       9 |
|   754 |       1 |
|   762 |      17 |
|   775 |       3 |
|   787 |       4 |
|   808 |       1 |
|   810 |       1 |
|   813 |       2 |
|   838 |       2 |
|   843 |       1 |
|   861 |       1 |
|   864 |       2 |
|   871 |       1 |
|   892 |       1 |
|   914 |       4 |
|   940 |       1 |
|   953 |       1 |
|   965 |       1 |
|   978 |       1 |
|  1041 |       1 |
|  1067 |       1 |
|  1105 |       1 |
|  1143 |       1 |
|  1207 |       1 |
|  6350 |       1 |
|  7122 |       1 |
|  7765 |       1 |
| 10160 |       1 |
|    NA |  381221 |

From both the distribution histogram of snowfall and the table with the
counts for each value of snowfall, the most commonly observed value of
snowfall is 0, with a count of 2,008,508. The second most common value
is NA with a count of 381,221. The reason that NA is a commonly observed
value for `snow` is because about one half of the stations report
precipitation only, and do not report data on the other weather
variables including `snow`. This results in many missing or “NA”
observations for `snow`. Additionally, the reason that 0 is the most
commonly observed value for `snow` is because the dataset contains data
from New York state weather stations only. While it does snow sometimes
during the winter in New York state, it is not snowing for the majority
of the year. This results in many values of 0 for the amount of snowfall
for dates during the spring, summer, and fall months.

NOTE: Running this analysis revealed that there is 1 record with a value
of -13 for `snow`. This indicates that the dataset may require
additional cleaning, as this value is outside of the reasonable range
because the amount of snowfall cannot be less than 0.

## Plot of average max temperature in January and in July in each station across years

Below, a two-panel scatterplot depicting the average maximum temperature
in the months of January and in July in each station across years are
side by side. To create the plot, separate objects were created for the
January and July plots. `id`, `year`, and `month` were grouped together
in order to calculate the mean of `tmax` for every unique combination of
those 3 variables. A new `mean_tmax` variable was created to calculate
the mean maximum temperature for each station separately across each
year. Then, `ggplot()` was used to plot points with `year` on the x axis
and `mean_max` on the y axis. `theme()` was used to rotate the text on
the x axis to make it easier to read and the legend was surpressed
because the 700 stations made it too large.

``` r
jan_tmax_point = 
  ny_noaa_df %>%
  group_by(id, year, month) %>% 
  filter(month == "01") %>% 
  mutate(mean_tmax = mean(tmax, na.rm = TRUE)) %>% 
  ggplot(aes(x = year, y = mean_tmax, group = id, color = id)) + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) + geom_point(show.legend = FALSE) +
  ggtitle("Avg max temp in January")

jul_tmax_point = 
  ny_noaa_df %>%
  group_by(id, year, month) %>% 
  filter(month == "07") %>% 
  mutate(mean_tmax = mean(tmax, na.rm = TRUE)) %>% 
  ggplot(aes(x = year, y = mean_tmax, group = id, color = id)) + 
  theme(axis.text.x = element_text(angle = 90,hjust = 1)) + geom_point(show.legend = FALSE) +
  ggtitle("Avg max temp in July")

jan_tmax_point + jul_tmax_point
## Warning: Removed 90613 rows containing missing values (geom_point).
## Warning: Removed 94457 rows containing missing values (geom_point).
```

![](p8105_hw3_sef2183_files/figure-gfm/problem%203%20max%20temp%20geom%20point%20plots-1.png)<!-- -->

Additionally, the same data is plotted below except using `geom_line` in
order to visualize the trends a bit easier:

``` r
jan_tmax_line = 
  ny_noaa_df %>%
  group_by(id, year, month) %>% 
  filter(month == "01") %>% 
  mutate(mean_tmax = mean(tmax, na.rm = TRUE)) %>% 
  ggplot(aes(x = year, y = mean_tmax, group = id, color = id)) + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) + geom_line(show.legend = FALSE) + ylab("mean maximum temperature (C)") + ggtitle("Avg max temp in January")

jul_tmax_line = 
  ny_noaa_df %>%
  group_by(id, year, month) %>% 
  filter(month == "07") %>% 
  mutate(mean_tmax = mean(tmax, na.rm = TRUE)) %>% 
  ggplot(aes(x = year, y = mean_tmax, group = id, color = id)) + 
  theme(axis.text.x = element_text(angle = 90,hjust = 1)) + geom_line(show.legend = FALSE) + ylab("mean maximum temperature (C)") + ggtitle("Avg max temp in July")

jan_tmax_line + jul_tmax_line
## Warning: Removed 90055 row(s) containing missing values (geom_path).
## Warning: Removed 93837 row(s) containing missing values (geom_path).
```

![](p8105_hw3_sef2183_files/figure-gfm/problem%203%20max%20temp%20geom%20line%20plots-1.png)<!-- -->

-   There is somewhat of an observable structure in the data. The mean
    maximum temperature for both the months of January and July
    oscillate higher and lower, with high peaks occurring roughly every
    4 years. Most of the data follows the same general oscillating
    pattern, however there are some outliers.
-   There are outliers in the data for both months. In January, there
    was a weather station that recorded a very low mean average
    temperature of about -16 degrees C in 1982. In July, there was also
    a weather station that recorded a low mean average temperature of
    about 19 degrees C in 1984, an even temperature of about 14 degrees
    C around 1988, and outliers of about 18 and 19 degrees C in 2004 and
    2007.

## Plot of tmax vs tmin for the full dataset (panel 1) and the distribution of snowfall values greater than 0 and less than 100 separately by year (panel 2)

Below, a two-panel plot depicting the minimum temperature vs. the
maximum temperature for the full dataset as well as the distribution of
snowfall values greater than 0 and less than 100 are displayed side by
side. For the first plot, an object was created and `ggplot()` was used
to plot the maximum temperatures against the minimum temperatures in the
entire dataset. Rather than a scatterplot, a hexagonal heatmap was
created to display the density coloring of the data points. For the
second plot, the dataset was filtered to include only extreme values of
snowfall less than 0 and greater than 100 and grouped by year.
`ggplot()` was used to create a distribution (density) plot using
`geom_violin()`.

``` r
i_p = ny_noaa_df %>%
  ggplot(aes(x = tmin, y = tmax)) +  
  theme(legend.position = "bottom") + geom_hex() + xlab("minimum temperature (C)") + ylab("maximum temperature (C)") + 
  ggtitle("Max temp vs. min temp")

ii_p = ny_noaa_df %>%
  filter(snow < 0 | snow > 100) %>% 
  group_by(year) %>% 
  ggplot(aes(x = year, y = snow)) + 
  theme(axis.text.x = element_text(angle = 90,hjust = 1)) + geom_violin() + ylab("snowfall (mm)") +
  ggtitle("Extreme snowfall by year")

i_p + ii_p
## Warning: Removed 1136276 rows containing non-finite values (stat_binhex).
```

![](p8105_hw3_sef2183_files/figure-gfm/problem%203%20tmax%20vs%20tmin%20and%20snowfall%20plots-1.png)<!-- -->
